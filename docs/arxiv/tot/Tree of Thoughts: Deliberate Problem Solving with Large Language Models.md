
Search
Write
Sign up

Sign in



üìú On short of ‚ÄúTree of Thoughts: Deliberate Problem Solving with Large Language Models‚Äù
Minh Le Duc
Minh Le Duc

¬∑
Follow

9 min read
¬∑
Jun 26, 2024
1




Abstract: Language models are increasingly used for problem-solving, but they often struggle with tasks requiring exploration or strategic lookahead. A new framework called ‚ÄúTree of Thoughts‚Äù (ToT) is introduced to improve these models. ToT allows deliberate decision-making, considering multiple reasoning paths and self-evaluating choices. Experiments show ToT significantly enhances language models‚Äô problem-solving abilities on tasks like Game of 24, Creative Writing, and Mini Crosswords, with a 74% success rate.

Keywords: LLMs, prompt engineering, AI reasonings, search algorithms.


Image generated by Playground
Introduction
I saw this appealing concept ‚Äî Tree-of-Thoughts (ToT) ‚Äî as a promising development for improving LLM‚Äôs generated answers by altering the prompting procedure. I would say that ToT is an innovative framework that allows language models to think like humans, explore multiple ‚Äúthoughts‚Äù, and make conscious decisions. As a result, we can say that there is a way for AI systems that truly understand and solve complex problems.


Image generated by Playground
Talking about ToT, it is a generalization of Chain-of-Thought (CoT), which is a very well-known technique to guide an LLM how to behave by a coherent language sequence that serves as a meaningful intermediate step toward problem solving. To be more specific, CoT is a few chain of thought demonstrations are provided as exemplars in prompting. CoT appears to be an effective and ease-to-use prompting technique; yet, it has a strict, linear approach that forces the model down a single path of reasoning and prevents it from exploring alternative possibilities. This tunnel vision can lead to dead ends and missed discoveries, limiting its ability to address complicated challenges. Furthermore, without a built-in self-evaluation mechanism, the model is unable to detect and repair its own flaws, potentially leading to inaccurate or unreliable results.

By saying ToT generalizes over the CoT, I want to talk about ToT‚Äôs adaptability. Not only does it provide a multiple CoT from a single input, but it also overcome its predecessor‚Äôs lackages. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices.This ‚Äútree‚Äù metaphor reflects the core of ToT by demonstrating its ability to branch out, explore new ideas, and even retrace if required, making it significantly more versatile than CoT‚Äôs linear approach.

Consider a kid who is locked in a strict pattern, doing math problems using the same formula every time. That‚Äôs how CoT prompting feels: linear and rigid. In contrast, ToT is similar to a student who can experiment with numerous tactics, branching out to investigate other approaches. ToT, in my opinion, is a breakthrough advance since it allows language models to think more like people, adjusting to difficult issues and exploring many answers.


Image generated by DALL-E 3.
As a part of ‚Äúüìú On short of‚Ä¶‚Äù, today‚Äôs journey is to gain a crisp and clear understanding of the Tree of Thoughts. During the voyage, we will look at the underlying notion of ToT to address important issues such as: What is ToT and why do we need it? Following that, we test our knowledge by doing an experiment using the ToT schema. The content of this writing is structured as follows:

Tree of Thoughts: we capture several key points of this architecture.
Code Implementation: we conduct an experiment that our prompting technique follows the ToT schema.
Conclusion: we review what we have done during our journey, also, we discuss about advantages and disadvantages of the technique.
Let‚Äôs dive in!

Tree-of-Thoughts (ToT)
Concepts
Personally, the concept of ToT is particularly beautiful since it is based on an observation about how humans solve problems. Humans seek a combinatorial problem space, which is a tree with nodes indicating partial answers and branches representing operators that modify those solutions. Heuristics let problem solvers explore the problem space and steer them toward a solution by selecting which branch to take.


Image from the articles. ToT allows broad issue solving using LMs due to their generality, modularity, flexibility, and simplicity. It allows for varied base LM, thought decomposition, generation, evaluation, and search procedures, accommodating different problem properties and resource constraints.
Think of me as an AI brainiac, tackling a tricky math problem. My mission? To find the answer, not just any answer, but the right one! Now, I don‚Äôt solve problems like a calculator, chugging through numbers in a straight line. Instead, it‚Äôs more like exploring a tangled jungle gym.

Imagine each bar and ring on the gym is like a potential solution, and the various paths you can take are like different ways of thinking about the problem. I can jump from one bar to another, trying out different approaches. All the while, I‚Äôm keeping track of which paths seem promising and which lead to dead ends, just like we do when we‚Äôre stuck on a puzzle.

To navigate this jungle gym of ideas, I use special ‚Äúsearch strategies.‚Äù One strategy is like checking out every bar on one level before moving to the next. Another is like focusing on one long path at a time until I reach the end (or fall off!). By using these strategies, I can explore different solutions systematically, just like a detective piecing together clues.

Totally dig ToT, it‚Äôs like a jungle gym of ideas where AI coaches help us climb towards the right answer, mimicking human problem-solving!

How does it work?
As previously said, ToT relies on human intuition when solving difficulties. The combinatorial problem space is represented as a tree, with nodes representing partial solutions and branches corresponding to operators that modify them. A solution occurs when a branch is chosen by heuristics that assist in navigating the issue space and guiding the problem solver to a solution.

The ToT paradigm highlights two key explore:

Allowing exploring different continuations within a thought process ‚Äî the branches of the tree ‚áí Locally.
Allowing incorporate any type of planning, lookahead, or backtracking to help evaluate these different options ‚áí Globally.
ToT frames any problem as a search over a tree, where each node is a state representing a partial solution with the input and the sequence of thoughts so far. A specific instantiation of ToT involves answering four questions:

How to decompose the intermediate process into thought steps (Thought decomposition)?
How to generate potential thoughts from each state (Thought generator)?
How to heuristically evaluate states (State evaluator)?
What search algorithm to use (Search algorithms)?
Thought decomposition: ToT leverages problem properties to design and decompose intermediate thought steps. Thoughts can be small enough for LMs to generate diverse samples and large enough for evaluation of their problem-solving potential.

Thought generator: A thought would be used to generate several candidate for the next thought steps. There are 2 strategies for generating, namely, Sample and Propose. Following the former, we sample i.i.d. thoughts from a CoT prompt. Meanwhile, the latter propose thoughts sequentially using a ‚Äúpropose prompt‚Äù (This works best when the thought space is more confined (e.g., each thought is only a word or a line), so proposing various thoughts in the same context minimizes repetition.).

State evaluator: Evaluates progress and serves as a guideline for the search algorithm in determining which states to explore next and in what sequence. The authors proposed a method that utilizes the LM to deliberately reason about states. There are two strategies to evaluate states either idepen

The first technique explores the concept of independent valuation of states in a system, using lookahead simulations and commonsense to generate scalar values or classifications that can be heuristically turned into values. The valuations are not perfect but should be approximately helpful for decision making, promoting ‚Äúgood‚Äù states and eliminating ‚Äúbad‚Äù ones.
Vote across states, where a ‚Äúgood‚Äù state is chosen by comparing different states in S. When problem success is harder to value, compare partial solutions and vote for the most promising one.
Search algorithms: When all states are generated and a tree is formed, we can plug and play different search algorithms depending on the tree structure (The article‚Äôs scope is on DFS and BFS).


Image from the article. Breadth-first search (BFS) is used in Game of 24 and Creative Writing to maintain a set of the most promising states per step. Depth-first search (DFS) explores the most promising state first until the final output is reached or the problem is impossible to solve.
ToT offers general problem-solving with LMs through its generality, modularity, adaptability, and convenience. It allows for varied base LM, thought decomposition, generation, evaluation, and search procedures, accommodating different problem properties and resource constraints.

Code Implementation
The good news is that trying out the Tree-of-Thoughts (ToT) technique seems accessible! The authors thoughtfully documented their implementation on the ToT Github repository, making it easier for you to follow along.

However, there‚Äôs one key limitation to be aware of: currently, the implementation only works with ChatGPT. This isn‚Äôt a random choice. The ToT approach relies on getting multiple responses from the user‚Äôs prompt. This back-and-forth interaction allows the system to build upon different ‚Äúthoughts‚Äù and refine its understanding of the problem. Unfortunately, not all Large Language Models (LLMs) are equipped to handle this kind of interactive prompting. I have tried several options, including Groq‚Äôs API and Gemini‚Äôs API, but none of them were able to provide a relevant functionality. As a result, ChatGPT seems to be the chosen tool for this specific implementation due to its ability to generate multiple responses to a single prompt.

Note: If you guys know anything cool other than Groq and Gemini, please, let me know in the comment section. Thanks!

Now, let‚Äôs go to the fun part!

We install the requirements for the ToT by:

git clone https://github.com/princeton-nlp/tree-of-thought-llm
cd tree-of-thought-llm
pip install -r requirements.txt
pip install -e .  # install `tot` package
Remember to setup your OpenAI‚Äôs API key. After that, we can put our hands on the Game24Task:

import argparse
from tot.methods.bfs import solve
from tot.tasks.game24 import Game24Task

# BFS experiment
args = argparse.Namespace(backend='gpt-4', temperature=0.7, task='game24', naive_run=False, prompt_sample=None, method_generate='propose', method_evaluate='value', method_select='greedy', n_generate_sample=1, n_evaluate_sample=3, n_select_sample=5)

# args = argparse.Namespace(backend='gpt-4', temperature=0.7, task='game24', naive_run=True, prompt_sample="cot", n_generate_sample=100) # cot_sampling
# args = argparse.Namespace(backend='gpt-4', temperature=0.7, task='game24', naive_run=True, prompt_sample="standard", n_generate_sample=100)  # standard_sampling

task = Game24Task()
ys, infos = solve(args, task, 900)
print(ys[0])
And the output would be something like (note it‚Äôs not deterministic, and sometimes the output can be wrong):

10 - 4 = 6 (left: 5 6 6)
5 * 6 = 30 (left: 6 30)
30 - 6 = 24 (left: 24)
Answer: (5 * (10 - 4)) - 6 = 24
Conclusion
In conclusion, the Tree-of-Thoughts (ToT) framework has emerged as a revolutionary approach to problem-solving for AI. By mimicking the human ability to navigate a ‚Äújungle gym‚Äù of ideas, ToT empowers AI to explore solutions strategically and tackle complex tasks in a multi-step fashion. We‚Äôve delved into the core concepts behind ToT, from its inspiration in human reasoning to its practical applications. We‚Äôve even explored how to get your hands dirty and install ToT, opening the door for you to witness its problem-solving magic firsthand.

This journey into ToT isn‚Äôt just about equipping AI with powerful tools; it‚Äôs a window into the fascinating world of human thought processes. As we continue to refine ToT and explore its potential, we unlock exciting possibilities for collaboration between humans and AI.

My future work would be explore more prompting techiques so that we can improve our results when dealing with LLMs. In addition, I would refine the code so that it can work well on other popular API, such as Groq and Gemini. Stay tune!

Thank you for reading this article; I hope it added something to your knowledge bank! Just before you leave:

üëâ Be sure to clap and follow me. It would be a great motivation for me.

üëâFollow me: LinkedIn | Github | Substack

References
Brown et al. ‚Äî Language Models are Few-Shot Learners ‚Äî URL: https://arxiv.org/abs/2005.14165
Wei et al. ‚Äî Chain-of-Thought Prompting Elicits Reasoning in Large Language Models ‚Äî URL: https://arxiv.org/abs/2201.11903
Llm
Prompt
Prompt Engineering
AI
Tot
1



Minh Le Duc
Written by Minh Le Duc
160 Followers
¬∑
171 Following
AI Engineer | I write and share what I know ü•≥

Follow


No responses yet

Write a response

What are your thoughts?

Cancel
Respond
More from Minh Le Duc
Python Best Practices Every Coder Should Know üèÜ
Minh Le Duc
Minh Le Duc

Python Best Practices Every Coder Should Know üèÜ
Make Your Code Clean, Secure, and Maintainable
Mar 4
31
2
Boost Your RAG Performance with Tavily Search API
Minh Le Duc
Minh Le Duc

Boost Your RAG Performance with Tavily Search API
Unlock Faster, More Relevant Results
Jul 29, 2024
56
2
On short of ‚ÄúReWOO: Decoupling Reasoning from Observations
for Efficient Augmented Language Models‚Äù
Minh Le Duc
Minh Le Duc

On short of ‚ÄúReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models‚Äù
Exploring the Potential of Decoupled Reasoning
Jul 9, 2024
12
Let‚Äôs read top LLM papers in personalizing AI in April 2024
Minh Le Duc
Minh Le Duc

Let‚Äôs read top LLM papers in personalizing AI in April 2024
Stay Up to Date with Latest LLMs Research.
Apr 29, 2024
7
See all from Minh Le Duc
Recommended from Medium
10 AI Tools That Replace a Full Dev Team (Almost)
Let‚Äôs Code Future
In

Let‚Äôs Code Future

by

TheMindShift

10 AI Tools That Replace a Full Dev Team (Almost)
The future isn‚Äôt coming‚Ää‚Äî‚Ääit‚Äôs already here. And it‚Äôs writing your code, fixing bugs, and even designing your UI.

Apr 6
1.5K
61
Kai Aizen‚Äôs P.R.O.M.P.T.S
The JailBreakChef
In

The JailBreakChef

by

Kai Aizen | SnailSploit

The Last Prompt Engineering Guide You‚Äôll Ever Read‚Ää‚Äî‚ÄäIntroducing P.R.O.M.P.T
While I find myself quite engaged with the advancements in agentic Large Language Models (LLMs), I can‚Äôt help but notice the continuous‚Ä¶
Mar 17
10
The 3-Level Prompting System That Makes AI Insanely Useful
Age of Awareness
In

Age of Awareness

by

Eva Keiffenheim

The 3-Level Prompting System That Makes AI Insanely Useful
Learn the science-backed, high-impact way to design prompts that think, create, and solve like a human partner.

Apr 9
1.6K
27
How Google Quietly Took the Lead in the AI Race with Gemini 2.5
Artificial Corner
In

Artificial Corner

by

The PyCoach

How Google Quietly Took the Lead in the AI Race with Gemini 2.5
This model isn‚Äôt just smart on paper

5d ago
985
24
This new IDE from Google is an absolute game changer
Coding Beauty
In

Coding Beauty

by

Tari Ibaba

This new IDE from Google is an absolute game changer
This new IDE from Google is seriously revolutionary.

Mar 12
4.3K
254
Is Chain-of-Thought Prompting Still Useful?
Micheal Lanham
Micheal Lanham

Is Chain-of-Thought Prompting Still Useful?
Exploring the Value and Evolution of AI‚Äôs Favorite Reasoning Technique in 2025

Mar 28
23
See more recommendations
Help

Status

About

Careers

Press

Blog

Privacy

Rules

Terms

Text to speech

